{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ew76R7bvzh5"
      },
      "source": [
        "Loading the California Housing  Dataset and visualizing statistics (using pandas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3cpm56Wvzh8"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqTMUlbpvzh9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Access the target variable (data labels)\n",
        "target = dataset.target\n",
        "target_names = dataset.target_names\n",
        "\n",
        "# Print the name of the target variable\n",
        "print(\"target_names\")\n",
        "print(target_names)\n",
        "# Print the feature names\n",
        "print(\"Feature Names:\")\n",
        "print(feature_names)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(X_full, columns=feature_names)\n",
        "\n",
        "\n",
        "# Calculate statistics for each feature using the describe() function\n",
        "statistics = df.describe()\n",
        "\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8Bk5ADlvziA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Select the desired features\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [list(feature_names).index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "\n",
        "# Create a pandas DataFrame with the selected features\n",
        "df = pd.DataFrame(X, columns=features)\n",
        "\n",
        "\n",
        "# Calculate statistics for each feature using the describe() function\n",
        "statistics = df.describe()\n",
        "\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVJm-8sMvziB"
      },
      "source": [
        "Loading the California Housing  Dataset and visualizing statistics (without using pandas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq_csDb-vziB"
      },
      "outputs": [],
      "source": [
        "# based on https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "\n",
        "\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "feature_mapping = {\n",
        "    \"MedInc\": \"Median income in block\",\n",
        "    \"HouseAge\": \"Median house age in block\",\n",
        "    \"AveRooms\": \"Average number of rooms\",\n",
        "    \"AveBedrms\": \"Average number of bedrooms\",\n",
        "    \"Population\": \"Block population\",\n",
        "    \"AveOccup\": \"Average house occupancy\",\n",
        "    \"Latitude\": \"House block latitude\",\n",
        "    \"Longitude\": \"House block longitude\",\n",
        "}\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [feature_names.index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "\n",
        "means = np.mean(X, axis=0)\n",
        "stds = np.std(X, axis=0)\n",
        "percentiles_25 = np.percentile(X, 25, axis=0)\n",
        "percentiles_50 = np.percentile(X, 50, axis=0)\n",
        "percentiles_75 = np.percentile(X, 75, axis=0)\n",
        "\n",
        "maximums = np.max(X, axis=0)\n",
        "minimums = np.min(X, axis=0)\n",
        "\n",
        "# Display the statistics for each feature\n",
        "for i, feature in enumerate(features):\n",
        "    print(\"Feature:\", feature)\n",
        "    print(\"Mean:\", means[i])\n",
        "    print(\"Standard Deviation:\", stds[i])\n",
        "    print(\"25th Percentile:\", percentiles_25[i])\n",
        "    print(\"50th Percentile (Median):\", percentiles_50[i])\n",
        "    print(\"75th Percentile:\", percentiles_75[i])\n",
        "    print(\"Maximum:\", maximums[i])\n",
        "    print(\"Minimum:\", minimums[i])\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewSKSB7BvziC"
      },
      "source": [
        "Visualizing data after and before the normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-LnSbNtvziC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Select the desired features\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [list(feature_names).index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "df = pd.DataFrame(X_full, columns=feature_names)\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply Min-Max Scaling to the selected features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot the data before normalization\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(df[\"MedInc\"], df[\"AveOccup\"])\n",
        "plt.xlabel(\"Median Income\")\n",
        "plt.ylabel(\"Average Occupancy\")\n",
        "plt.title(\"Data Before Normalization\")\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After Min-Max Scaling\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
        "statistics = df_scaled.describe()\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n",
        "\n",
        "X_MinMaxScaler=X_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvkFodD0vziC"
      },
      "outputs": [],
      "source": [
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_MinMaxScaler[:, 0], X_MinMaxScaler[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After MinMaxScaler\")\n",
        "plt.ylim(-0.01, 0.05)  # Set the y-axis limits for zooming\n",
        "plt.xlim(-0.1, 1.1)  # Set the x-axis limits for zooming\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WrHEia5vziD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Select the desired features\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [list(feature_names).index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "df = pd.DataFrame(X_full, columns=feature_names)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply StandardScaler Scaling to the selected features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot the data before normalization\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(df[\"MedInc\"], df[\"AveOccup\"])\n",
        "plt.xlabel(\"Median Income\")\n",
        "plt.ylabel(\"Average Occupancy\")\n",
        "plt.title(\"Data Before Normalization\")\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After StandardScaler\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
        "statistics = df_scaled.describe()\n",
        "\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n",
        "\n",
        "X_StandardScaler=X_scaled\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f2LqOj8vziE"
      },
      "outputs": [],
      "source": [
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_StandardScaler[:, 0], X_StandardScaler[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After StandardScaler\")\n",
        "plt.ylim(-0.3, 0.3)  # Set the x-axis limits for zooming\n",
        "plt.xlim(-2.1, 4.4)  # Set the y-axis limits for zooming\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjGQBpMvvziE"
      },
      "source": [
        "Scale features using statistics that are robust to outliers.\n",
        "\n",
        "It involves eliminating the median and rescaling the data based on the interquartile range (IQR), which is the range between the 25th and 75th percentiles (1st quartile and 3rd quartile, respectively).\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbySBb5DvziE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Select the desired features\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [list(feature_names).index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "df = pd.DataFrame(X_full, columns=feature_names)\n",
        "# Initialize the RobustScaler\n",
        "scaler = RobustScaler(quantile_range=(25, 75))\n",
        "\n",
        "\n",
        "# Apply RobustScaler Scaling to the selected features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot the data before normalization\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(df[\"MedInc\"], df[\"AveOccup\"])\n",
        "plt.xlabel(\"Median Income\")\n",
        "plt.ylabel(\"Average Occupancy\")\n",
        "plt.title(\"Data Before Normalization\")\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After RobustScaler\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
        "statistics = df_scaled.describe()\n",
        "\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n",
        "\n",
        "X_RobustScaler=X_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ7oLKVwvziF"
      },
      "outputs": [],
      "source": [
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_RobustScaler[:, 0], X_RobustScaler[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After RobustScaler\")\n",
        "plt.ylim(-2, 4)  # Set the y-axis limits for zooming\n",
        "plt.xlim(-2, 4)  # Set the x-axis limits for zooming\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59BSFkKgvziF"
      },
      "outputs": [],
      "source": [
        "# Plot the data after different scaling methods\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot the data after Min-Max Scaling\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X_MinMaxScaler[:, 0], X_MinMaxScaler[:, 1])\n",
        "plt.xlim(-5, 5)  # Set the x-axis limits for zooming\n",
        "plt.ylim(-5, 5)  # Set the y-axis limits for zooming\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After Min-Max Scaling\")\n",
        "\n",
        "# Plot the data after Standard Scaling\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X_StandardScaler[:, 0], X_StandardScaler[:, 1])\n",
        "plt.xlim(-5, 5)  # Set the x-axis limits for zooming\n",
        "plt.ylim(-5, 5)  # Set the y-axis limits for zooming\n",
        "plt.xlabel(\"Standardized Median Income\")\n",
        "plt.ylabel(\"Standardized Average Occupancy\")\n",
        "plt.title(\"Data After Standard Scaling\")\n",
        "\n",
        "# Plot the data after Robust Scaling\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(X_RobustScaler[:, 0], X_RobustScaler[:, 1])\n",
        "plt.xlim(-5, 5)  # Set the x-axis limits for zooming\n",
        "plt.ylim(-5, 5)  # Set the y-axis limits for zooming\n",
        "plt.xlabel(\"Robustly Scaled Median Income\")\n",
        "plt.ylabel(\"Robustly Scaled Average Occupancy\")\n",
        "plt.title(\"Data After Robust Scaling\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03JkcytQvziG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMl-1YK5vziG"
      },
      "source": [
        "QuantileTransformer (uniform output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0tpbtYivziG"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Select the desired features\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [list(feature_names).index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "df = pd.DataFrame(X_full, columns=feature_names)\n",
        "# Initialize the Scaler\n",
        "scaler =  QuantileTransformer(output_distribution=\"uniform\")\n",
        "\n",
        "# Apply Scaling to the selected features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot the data before normalization\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(df[\"MedInc\"], df[\"AveOccup\"])\n",
        "plt.xlabel(\"Median Income\")\n",
        "plt.ylabel(\"Average Occupancy\")\n",
        "plt.title(\"Data Before Normalization\")\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After Quantile Transformer Scaling (Uniform)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
        "statistics = df_scaled.describe()\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n",
        "\n",
        "X_QuantileTransformer=X_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcXkzSd-vziH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "# Load the California housing dataset\n",
        "dataset = fetch_california_housing()\n",
        "X_full, y_full = dataset.data, dataset.target\n",
        "feature_names = dataset.feature_names\n",
        "\n",
        "# Select the desired features\n",
        "features = [\"MedInc\", \"AveOccup\"]\n",
        "features_idx = [list(feature_names).index(feature) for feature in features]\n",
        "X = X_full[:, features_idx]\n",
        "df = pd.DataFrame(X_full, columns=feature_names)\n",
        "# Initialize the Scaler\n",
        "scaler =  QuantileTransformer(output_distribution=\"normal\")\n",
        "\n",
        "# Apply Scaling to the selected features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Plot the data before and after normalization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot the data before normalization\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(df[\"MedInc\"], df[\"AveOccup\"])\n",
        "plt.xlabel(\"Median Income\")\n",
        "plt.ylabel(\"Average Occupancy\")\n",
        "plt.title(\"Data Before Normalization\")\n",
        "\n",
        "# Plot the data after normalization\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1])\n",
        "plt.xlabel(\"Normalized Median Income\")\n",
        "plt.ylabel(\"Normalized Average Occupancy\")\n",
        "plt.title(\"Data After Quantile Transformer Scaling (Normal)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
        "statistics = df_scaled.describe()\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "# Display the statistics for each feature\n",
        "print(statistics)\n",
        "\n",
        "X_QuantileTransformer=X_scaled\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
